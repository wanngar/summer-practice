<h1>Semantic segmentation oil spills on SAR images</h1>
<img src='https://thehill.com/wp-content/uploads/sites/2/2023/11/AP23325662807033-e1700598430446.jpg'>
<h2>Introduction</h2>
<p>Among the different types of marine pollution, oil is a major threat to the sea ecosystems. The source of the oil pollution can be located on the mainland or directly at sea. Sea-based sources are discharges coming from ships or offshore platforms. Oil pollution from sea-based sources can be accidental or deliberate. Fortunately, the number of marine accidents and the volume of oil released accidentally are on the decline. On the other side, routine tanker operations can lead still to the release of oily ballast water and tank washing residues. Furthermore, fuel oil sludge, engine room wastes and foul bilge water produced by all type of ships, also end up in the sea. In the last decade maritime transportation has been growing steadily. More ships also increase the potential number of illegal oil discharges. Both oil tankers and other kinds of ships are among the suspected offenders of illegal discharges.</p>
<p>The different tools to detect and monitor oil spills are vessels, airplanes, and satellites. Vessels, especially if equipped with specialised radars, can detect oil at sea but they can cover a very limited area. The vessel, however, remains necessary in case oil sampling is required. The main systems to monitor sea-based oil pollution are the use of airplanes and satellites equipped with Synthetic Aperture Radar (SAR). SAR is an active microwave sensor, which captures two dimensional images. The brightness of the captured image is a reflection of the properties of the target-surface. The possibility of detecting an oil spill in a SAR image relies on the fact that the oil film decreases the backscattering of the sea surface resulting in a dark formation that contrasts with the brightness of the surrounding spill-free sea. Spaceborne SAR sensors are extensively used for the detection of oil spills in the marine environment, as they are independent from sun light, they are not affected by cloudiness, they cover large areas and are more cost-effective than air patrolling. [<a src=https://doi.org/10.3390/s8106642>1</a>]</p>
<h2>Semantic Segmentation</h2>
<image src='https://www.ayadata.ai/wp-content/uploads/2023/04/semantic-segmentation-1.jpg'>
<p>The goal of semantic segmentation is to group pixels in a meaningful way. Pixels that belong to a road, people, automobiles, or trees, for example, must be grouped individually. As a result, semantic segmentation does pixel-by-pixel categorization, such as determining if a pixel is part of a traversable road, an automobile, or a pedestrian. For self-driving automobiles and robotic navigation systems, this is critical.</p>
<p>Although semantic segmentation is described as the process of identifying and labeling images at the pixel level, it is sometimes mistaken for instance segmentation. The major difference is that with semantic segmentation, all pixels that belong to the same class have the same pixel value.</p>
<p>Semantic segmentation for computer vision is used in a variety of fields, including:</p>
<ul><li>Recognizing people by their faces</li>
<li>Recognition of handwriting</li>
<li>Image search in the virtual world</li>
<li>Automobiles that drive themselves</li>
<li>Mapping for satellite and aerial imagery for the fashion industry and virtual try-on</li>
<li>Imaging and diagnostics in medicine</li></ul>
<p>In general, semantic segmentation is utilized for more complex tasks than other image annotation methods, since it allows robots to generate a higher-level judgment. For a better understanding, weâ€™ll look towards semantic segmentation common designs in the future. [<a src='https://towardsai.net/p/l/machine-learning-7'>2</a>]</p>
<h2>Dataset Description</h2>
<image src='https://m4d.iti.gr/wp-content/uploads/2021/01/article-jan21-2048x798.jpg'>
<p>Oil Spill Detection Dataset contains jpg images extracted from satellite Synthetic Aperture Radar (SAR) data depicting oil spills and other relevant instances, as well as their corresponding ground truth masks. Initial SAR data were collected from the European Space Agency (ESA) database, the Copernicus Open Access Hub acquired via the Sentinel-1 European Satellite missions. The required geographic coordinates and time of the confirmed oil spills were provided by the European Maritime Safety Agency (EMSA) based on the CleanSeaNet service records, covering a period from 28/09/2015 up to 31/10/2017.

The developed dataset (~400MB) contains around 1000 images for training and 110 images for testing, depicting instances of 5 classes, namely oil spill, look-alike, land, ship and sea areas. [<a src=https://m4d.iti.gr/oil-spill-detection-dataset/>3</a>]</p>
<a src=https://www.kaggle.com/datasets/nabilsherif/oil-spill/data>Source link of dataset</a> [4]
<h2>Neural Network Architecture</h2>
<image src='https://developers.arcgis.com/python/guide/images/unet.png'>
<p>U-net was originally invented and first used for biomedical image segmentation. Its architecture can be broadly thought of as an encoder network followed by a decoder network. Unlike classification where the end result of the the deep network is the only important thing, semantic segmentation not only requires discrimination at pixel level but also a mechanism to project the discriminative features learnt at different stages of the encoder onto the pixel space.</p>

<p>The encoder is the first half in the architecture diagram. It usually is a pre-trained classification network like VGG/ResNet where you apply convolution blocks followed by a maxpool downsampling to encode the input image into feature representations at multiple different levels.</p>

<p>The decoder is the second half of the architecture. The goal is to semantically project the discriminative features (lower resolution) learnt by the encoder onto the pixel space (higher resolution) to get a dense classification. The decoder consists of upsampling and concatenation followed by regular convolution operations. [<a src='https://developers.arcgis.com/python/guide/how-unet-works/'>5</a>]</p>
<h2>Results and Metrics</h2>
